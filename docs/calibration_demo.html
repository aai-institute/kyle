<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>What is calibration? &mdash; Python 0.1.8.dev0 documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Dirichlet fake classifiers" href="fake_classifiers.html" />
    <link rel="prev" title="kyle library and game" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> Python
          </a>
              <div class="version">
                0.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p><span class="caption-text">Guides and Tutorials</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">What is calibration?</a></li>
<li class="toctree-l1"><a class="reference internal" href="#Model-calibration">Model calibration</a></li>
<li class="toctree-l1"><a class="reference internal" href="#Model-agnostic-calibration">Model-agnostic calibration</a></li>
<li class="toctree-l1"><a class="reference internal" href="fake_classifiers.html">Dirichlet fake classifiers</a></li>
<li class="toctree-l1"><a class="reference internal" href="fake_classifiers.html#Analytical-results">Analytical results</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting-started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="metric_convergence_analysis.html">Case 1: RF and MLP on Synthetic Data</a></li>
</ul>
<p><span class="caption-text">Modules</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="kyle/index.html">Library Modules</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Python</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a></li>
      <li class="breadcrumb-item active">What is calibration?</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/calibration_demo.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars and line breaks on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
    white-space: pre;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="kn">from</span> <span class="nn">kyle.calibration</span> <span class="kn">import</span> <span class="n">ModelCalibrator</span>
<span class="kn">from</span> <span class="nn">kyle.models</span> <span class="kn">import</span> <span class="n">CalibratableModel</span>
<span class="kn">from</span> <span class="nn">kyle.metrics</span> <span class="kn">import</span> <span class="n">ECE</span>
<span class="kn">from</span> <span class="nn">kyle.calibration.calibration_methods</span> <span class="kn">import</span> <span class="n">TemperatureScaling</span>
<span class="kn">from</span> <span class="nn">kyle.sampling.fake_clf</span> <span class="kn">import</span> <span class="n">DirichletFC</span>
<span class="kn">from</span> <span class="nn">kyle.transformations</span> <span class="kn">import</span> <span class="n">MaxComponentSimplexAut</span>
<span class="kn">from</span> <span class="nn">kyle.evaluation</span> <span class="kn">import</span> <span class="n">EvalStats</span>
</pre></div>
</div>
</div>
<section id="What-is-calibration?">
<h1>What is calibration?<a class="headerlink" href="#What-is-calibration?" title="Permalink to this headline"></a></h1>
<p>When we talk about how good a machine learning model is, what we (generally) mean to ask is: How accurate is the model? While this is a good enough metric in many cases, we are, in fact, leaving out important information about the model. One such piece of information is concerned with whether the confidence of the model is in line with its accuracy. If it is, we say the model is calibrated.</p>
<p>To explain this concept in detail, let’s begin with an example. Suppose we want to predict whether a patient has cancer. We can simulate data with two classes i.e. <span class="math notranslate nohighlight">\(y \in \{0, 1\}\)</span> where <span class="math notranslate nohighlight">\(y=0\)</span> denotes a healthy patient and <span class="math notranslate nohighlight">\(y=1\)</span> denotes a patient who has cancer.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_samples</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">n_classes</span> <span class="o">=</span> <span class="mi">3</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_classification</span><span class="p">(</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span>
    <span class="n">n_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">n_informative</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
    <span class="n">n_redundant</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">n_classes</span><span class="o">=</span><span class="n">n_classes</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<p>We can then train a neural network on our data:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/runner/work/kyle/kyle/.tox/py/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn&#39;t converged yet.
  warnings.warn(
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>MLPClassifier(hidden_layer_sizes=(20, 20, 10))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">MLPClassifier</label><div class="sk-toggleable__content"><pre>MLPClassifier(hidden_layer_sizes=(20, 20, 10))</pre></div></div></div></div></div></div>
</div>
<p>and make predictions on new samples. Let’s see how our model performs on unseen examples:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">model_accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="sa">f</span><span class="s2">&quot;Model accuracy: </span><span class="si">{</span><span class="n">model_accuracy</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s2">%&quot;</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&#39;Model accuracy: 85.39999999999999%&#39;
</pre></div></div>
</div>
<p>That seems pretty good! One might think our job here is done: After all, the model predicts whether a person has cancer or not with decent accuracy. Unfortunately, accuracy of a model does not tell us the full story. This is so due to the fact that at inference time, for a given sample a model outputs confidence scores for each class. We then take the class with the highest confidence and interpret that as the prediction of the model.</p>
<p>This conversion of continuous (probability) to discrete (label) values can hide certain properties of the model. To illustrate this, let’s take two models – <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> – trained on the same data. Let’s further assume they have similar accuracy. Suppose we test both models with 10 healthy samples. <span class="math notranslate nohighlight">\(A\)</span> assigns probabilities <span class="math notranslate nohighlight">\((0.49, 0.51)\)</span> to all samples, whereas <span class="math notranslate nohighlight">\(B\)</span> assigns <span class="math notranslate nohighlight">\((0.1, 0.9)\)</span>. While <span class="math notranslate nohighlight">\(A\)</span> &amp; <span class="math notranslate nohighlight">\(B\)</span> will be wrong 100% of the time, notice
<span class="math notranslate nohighlight">\(A\)</span> being much closer to classifying the samples as belonging to the correct class compared to <span class="math notranslate nohighlight">\(B\)</span>.</p>
<p>Continuing with our previous example: Imagine that on all examples where the model was <span class="math notranslate nohighlight">\(95\)</span>% confident that the subject has cancer, it was correct <span class="math notranslate nohighlight">\(70\)</span>% of the time. Intuitively, it seems there’s something not quite right with the model: the model is over-confident in its predictions. This notion is formalized by the concept of calibration. We say a model is (strongly) calibrated when, for any confidence value <span class="math notranslate nohighlight">\(p \in [0, 1]\)</span>, prediction of a class with confidence <span class="math notranslate nohighlight">\(p\)</span>
is correct with probability <span class="math notranslate nohighlight">\(p\)</span>:</p>
<p><span class="math">\begin{equation}
P(\widehat{y}=y|\widehat{p}=p) = p \quad \forall p \in [0, 1]
\end{equation}</span></p>
<p>So, is our model calibrated? As we can see in the equation above, <span class="math notranslate nohighlight">\(\widehat{p}\)</span> is continuous, which means we cannot compute the equation with finite data. We can, however, develop empirical measures that approximate the true measure of (mis)calibration.</p>
<p>One simple way to get an empirical estimate of the model’s accuracy and confidence is to discretize the probability space. This is done by slicing <span class="math notranslate nohighlight">\(p\)</span> into <span class="math notranslate nohighlight">\(K\)</span> equal-sized bins. We can then calculate the accuracy and confidence for each bin:</p>
<p><span class="math">\begin{equation}
accuracy_{B_k} = \frac{1}{|B_k|} \sum_{m=1}^{|B_k|}1(\widehat{p}_m=p_m)
\end{equation}</span></p>
<p><span class="math">\begin{equation}
confidence_{B_k} = \frac{1}{|B_k|} \sum_{m=1}^{|B_k|}\widehat{p}_m
\end{equation}</span></p>
<p>We can now simply calculate the weighted average difference between the accuracy and confidence of the model over all bins:</p>
<p><span class="math">\begin{equation}
\sum_{k=1}^{K} \frac{|B_k|}{n} \Big|\:accuracy_{B_k} - confidence_{B_k} \Big|
\end{equation}</span></p>
<p>This is known as the <strong>Expected Calibration Error</strong> <span class="math notranslate nohighlight">\((ECE).\)</span> As can be seen, <span class="math notranslate nohighlight">\(ECE=0\)</span> if a model is perfectly calibrated. Let’s calculate the <span class="math notranslate nohighlight">\(ECE\)</span> for our model with <span class="math notranslate nohighlight">\(10\)</span> bins:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ece</span> <span class="o">=</span> <span class="n">ECE</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Evaluate uncalibrated predictions</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">pre_calibration_ece</span> <span class="o">=</span> <span class="n">ece</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

<span class="sa">f</span><span class="s2">&quot;ECE before calibration: </span><span class="si">{</span><span class="n">pre_calibration_ece</span><span class="si">}</span><span class="s2">&quot;</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&#39;ECE before calibration: 0.09662671533310493&#39;
</pre></div></div>
</div>
<p>We can also visualize the extent of miscalibration by plotting the model’s confidence <em>(x-axis)</em> vs. the ground truth probability <em>(y-axis)</em>. For a perfectly calibrated model, the plot should be <span class="math notranslate nohighlight">\(y=x\)</span>. Let’s see how our model fares:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">eval_stats</span> <span class="o">=</span> <span class="n">EvalStats</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">class_labels</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_classes</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">eval_stats</span><span class="o">.</span><span class="n">plot_reliability_curves</span><span class="p">(</span>
    <span class="p">[</span><span class="s2">&quot;top_class&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">display_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="n">n_bins</span><span class="o">=</span><span class="mi">8</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/calibration_demo_18_0.png" src="_images/calibration_demo_18_0.png" />
</div>
</div>
<p>The density of predictions is distributed highly inhomogeneously on the unit interval, some bins have few members and the estimate of the reliability has high variance. This can be helped by employing the “quantile” binning strategy, also called adaptive binning</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">eval_stats</span><span class="o">.</span><span class="n">plot_reliability_curves</span><span class="p">(</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;top_class&quot;</span><span class="p">],</span> <span class="n">display_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n_bins</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;quantile&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/calibration_demo_20_0.png" src="_images/calibration_demo_20_0.png" />
</div>
</div>
<p>Now all bins have the same weight but different width. The pointwise reliability estimates have lower variance but there are wide gaps, thus requiring more interpolation. Both binning strategies have their advantages and disadvantages.</p>
<p>Okay, so our model is not calibrated as <span class="math notranslate nohighlight">\(ECE&gt;0\)</span>. Can we do anything to remedy the situation?</p>
</section>
<section id="Model-calibration">
<h1>Model calibration<a class="headerlink" href="#Model-calibration" title="Permalink to this headline"></a></h1>
<p>Indeed, we can improve the calibration of our model using various techniques. What’s more, we don’t need to train our model again; many calibration techniques are post-processing methods i.e. operating on the trained model’s output confidence scores. The output scores for calibration are typically obtained on a validation set.</p>
<p>In <code class="docutils literal notranslate"><span class="pre">kyle</span></code>, we have provided a <code class="docutils literal notranslate"><span class="pre">CalibratableModel</span></code> class which takes a model and, as the name suggests, makes it possible to calibrate that model. By default, we use a technique called <a class="reference external" href="https://arxiv.org/abs/1706.04599">Temperature scaling</a> for calibration.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create calibratable model</span>
<span class="n">calibration_method</span> <span class="o">=</span> <span class="n">TemperatureScaling</span><span class="p">()</span>
<span class="n">calibratable_model</span> <span class="o">=</span> <span class="n">CalibratableModel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">calibration_method</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>We also provide a <code class="docutils literal notranslate"><span class="pre">ModelCalibrator</span></code> class which holds the data to calibrate models:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create model calibrator and calibrate model</span>
<span class="n">calibrator</span> <span class="o">=</span> <span class="n">ModelCalibrator</span><span class="p">(</span>
    <span class="n">X_calibrate</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_calibrate</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">X_fit</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_fit</span><span class="o">=</span><span class="n">y_train</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<p>We now have everything ready to calibrate our model:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">calibrator</span><span class="o">.</span><span class="n">calibrate</span><span class="p">(</span><span class="n">calibratable_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Let’s see if calibrating the model improved the <span class="math notranslate nohighlight">\(ECE\)</span> score</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Passing X_test instead of X_calibrate in predict_proba() to make comparison with pre-calib model clear,</span>
<span class="c1"># same reasong for y_test in ece.compute()</span>
<span class="n">calibrated_confidences</span> <span class="o">=</span> <span class="n">calibratable_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">post_calibration_ece</span> <span class="o">=</span> <span class="n">ece</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">calibrated_confidences</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

<span class="sa">f</span><span class="s2">&quot;ECE before calibration: </span><span class="si">{</span><span class="n">pre_calibration_ece</span><span class="si">}</span><span class="s2">, ECE after calibration: </span><span class="si">{</span><span class="n">post_calibration_ece</span><span class="si">}</span><span class="s2">&quot;</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&#39;ECE before calibration: 0.09662671533310493, ECE after calibration: 0.020610631316900222&#39;
</pre></div></div>
</div>
<p>Great! <span class="math notranslate nohighlight">\(ECE\)</span> has improved. Let’s also plot a reliability curve to visually confirm the improvement in calibration.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">eval_stats</span> <span class="o">=</span> <span class="n">EvalStats</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">calibrated_confidences</span><span class="p">)</span>

<span class="n">eval_stats</span><span class="o">.</span><span class="n">plot_reliability_curves</span><span class="p">(</span><span class="n">class_labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="output_area docutils container">
<img alt="_images/calibration_demo_33_0.png" src="_images/calibration_demo_33_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/calibration_demo_33_1.png" src="_images/calibration_demo_33_1.png" />
</div>
</div>
<p>Wonderful! We have successfully improved our model’s calibration.</p>
</section>
<section id="Model-agnostic-calibration">
<h1>Model-agnostic calibration<a class="headerlink" href="#Model-agnostic-calibration" title="Permalink to this headline"></a></h1>
<p>You may have noticed that to evaluate (mis)calibration of a model, we don’t require the model itself. Rather, it is sufficient to have the confidence scores predicted by the model. This means we can abstract away the model and generate both the ground truth and confidence scores via sampling processes.</p>
<p>In <code class="docutils literal notranslate"><span class="pre">kyle</span></code> we have provided samplers that simulate different kinds of calibration properties. One such sampler is the <code class="docutils literal notranslate"><span class="pre">DirichletFC</span></code> class which provides calibrated ground truth and confidences by default.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sampler</span> <span class="o">=</span> <span class="n">DirichletFC</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Get 1000 calibrated fake confidence scores</span>
<span class="n">calibrated_samples</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">get_sample_arrays</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">ground_truth</span><span class="p">,</span> <span class="n">confidences</span> <span class="o">=</span> <span class="n">calibrated_samples</span>
</pre></div>
</div>
</div>
<p>Let’s evaluate the <span class="math notranslate nohighlight">\(ECE\)</span> for these samples:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ece</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">confidences</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.021226959445605285
</pre></div></div>
</div>
<p>Wait, the <span class="math notranslate nohighlight">\(ECE&gt;0\)</span>, how can we say that the samples are calibrated?</p>
<p>As mentioned earlier, we only have finite samples so true miscalibration can only be measured asymptotically. This means that the more samples we have, the more accurate would <span class="math notranslate nohighlight">\(ECE\)</span>’s estimate become. We can test this by generating <em>5x</em> as many samples as before and evaluating <span class="math notranslate nohighlight">\(ECE\)</span> again:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">calibrated_samples</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">get_sample_arrays</span><span class="p">(</span><span class="mi">5000</span><span class="p">)</span>
<span class="n">ground_truth</span><span class="p">,</span> <span class="n">confidences</span> <span class="o">=</span> <span class="n">calibrated_samples</span>

<span class="n">ece</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">confidences</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.012946787951753537
</pre></div></div>
</div>
<p>As expected, <span class="math notranslate nohighlight">\(ECE\)</span> goes down with more samples.</p>
<p>We can also systematically generate uncalibrated samples. For instance, the <code class="docutils literal notranslate"><span class="pre">ShiftingSimplexAutomorphism</span></code> shifts the confidence scores by adding a fixed vector with positive entries to the input and normalizing the result.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">overestimating_max</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">2</span>
    <span class="n">x</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="mi">4</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="n">mask</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="n">automorphism</span> <span class="o">=</span> <span class="n">MaxComponentSimplexAut</span><span class="p">(</span><span class="n">overestimating_max</span><span class="p">)</span>
<span class="n">shifted_sampler</span> <span class="o">=</span> <span class="n">DirichletFC</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">simplex_automorphism</span><span class="o">=</span><span class="n">automorphism</span><span class="p">)</span>

<span class="c1"># Get 1000 uncalibrated fake confidence scores</span>
<span class="n">uncalibrated_samples</span> <span class="o">=</span> <span class="n">shifted_sampler</span><span class="o">.</span><span class="n">get_sample_arrays</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
<span class="n">ground_truth</span><span class="p">,</span> <span class="n">confidences</span> <span class="o">=</span> <span class="n">uncalibrated_samples</span>
</pre></div>
</div>
</div>
<p>Let’s see if the uncalibrated nature of the samples is validated by <span class="math notranslate nohighlight">\(ECE\)</span>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ece</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">confidences</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.17290483432707532
</pre></div></div>
</div>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="kyle library and game" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="fake_classifiers.html" class="btn btn-neutral float-right" title="Dirichlet fake classifiers" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>